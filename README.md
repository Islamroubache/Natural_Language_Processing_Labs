<div align="center">

# üß† Natural Language Processing Labs

### *Master's Level NLP Course - Laboratory Exercises*

[![Python](https://img.shields.io/badge/Python-3776AB?style=for-the-badge&logo=python&logoColor=white)](https://www.python.org/)
[![NLTK](https://img.shields.io/badge/NLTK-154f3c?style=for-the-badge&logo=python&logoColor=white)](https://www.nltk.org/)
[![spaCy](https://img.shields.io/badge/spaCy-09A3D5?style=for-the-badge&logo=spacy&logoColor=white)](https://spacy.io/)
[![TensorFlow](https://img.shields.io/badge/TensorFlow-FF6F00?style=for-the-badge&logo=tensorflow&logoColor=white)](https://www.tensorflow.org/)
[![PyTorch](https://img.shields.io/badge/PyTorch-EE4C2C?style=for-the-badge&logo=pytorch&logoColor=white)](https://pytorch.org/)

---

*Complete solutions for Natural Language Processing laboratory exercises*  
**Higher School of Computer Science (08 May 1945) - Sidi Bel Abbes, Algeria**  
*1st Year Master's - AI & Data Science Specialization*

</div>

---

## üìö About This Repository

This repository contains comprehensive solutions for all laboratory exercises from the Natural Language Processing course. Each TP (Travaux Pratiques) builds upon fundamental NLP concepts, progressing from basic text preprocessing to advanced sequence modeling and machine translation.

---

## üéØ Laboratory Exercises

<table>
<tr>
<td width="50%">

### üìà TP-01: Preprocessing in NLP

**Foundation of Text Processing**

Essential preprocessing techniques that form the backbone of any NLP pipeline:

- **Tokenization** - Breaking text into meaningful units
- **Lowercasing** - Normalizing text case
- **Stopword Removal** - Filtering common words
- **Lemmatization & Stemming** - Reducing words to base forms

</td>
<td width="50%">

### üìà TP-02: Feature Extraction & Embeddings

**Transforming Text to Numbers**

Introduction to feature extraction and word representation techniques:

- **Bag of Words (BoW)** - Simple frequency-based representation
- **TF-IDF** - Term frequency-inverse document frequency
- **Word2Vec** - Dense word embeddings
- **GloVe** - Global vectors for word representation

</td>
</tr>
<tr>
<td width="50%">

### üìà TP-03: Advanced Feature Extraction

**Optimization & Enhancement**

Building upon TP-02 with improved techniques:

- Enhanced model performance
- Advanced embedding techniques
- Hyperparameter optimization
- Comparative analysis of methods

</td>
<td width="50%">

### üìà TP-04: Sequence Models

**Deep Learning for Sequential Data**

Exploring neural architectures for sequence processing:

- **RNNs** - Recurrent Neural Networks
- **LSTMs** - Long Short-Term Memory Networks
- **GRUs** - Gated Recurrent Units
- Sequence-to-sequence architectures

</td>
</tr>
<tr>
<td colspan="2">

### üìà TP-05: Machine Translation (English ‚Üí French)

**Neural Machine Translation**

Building an end-to-end translation system:

- Sequence-to-sequence models with attention
- Transformer-based architectures
- Encoder-decoder frameworks
- Translation quality evaluation

</td>
</tr>
</table>

---

## üõ†Ô∏è Tools & Technologies

<div align="center">

| Category | Technologies |
|----------|-------------|
| **Core Language** | ![Python](https://img.shields.io/badge/Python-3776AB?style=flat-square&logo=python&logoColor=white) Python 3.x |
| **Text Processing** | ![NLTK](https://img.shields.io/badge/NLTK-154f3c?style=flat-square&logo=python&logoColor=white) NLTK ‚Ä¢ ![spaCy](https://img.shields.io/badge/spaCy-09A3D5?style=flat-square&logo=spacy&logoColor=white) spaCy |
| **Embeddings** | ![Gensim](https://img.shields.io/badge/Gensim-0C2340?style=flat-square&logo=python&logoColor=white) Gensim (Word2Vec) |
| **Feature Extraction** | ![scikit-learn](https://img.shields.io/badge/scikit--learn-F7931E?style=flat-square&logo=scikit-learn&logoColor=white) scikit-learn (TF-IDF, BoW) |
| **Deep Learning** | ![TensorFlow](https://img.shields.io/badge/TensorFlow-FF6F00?style=flat-square&logo=tensorflow&logoColor=white) TensorFlow ‚Ä¢ ![PyTorch](https://img.shields.io/badge/PyTorch-EE4C2C?style=flat-square&logo=pytorch&logoColor=white) PyTorch |
| **Advanced Models** | ![Transformers](https://img.shields.io/badge/ü§ó_Transformers-FFD21E?style=flat-square) Hugging Face Transformers |

</div>


---

## üöÄ Getting Started

### Prerequisites

\`\`\`bash
Python 3.8+
pip or conda package manager
\`\`\`

### Installation

\`\`\`bash
# Clone the repository
git clone https://github.com/yourusername/nlp-labs.git
cd nlp-labs

# Install required packages
pip install -r requirements.txt

# Download NLTK data
python -c "import nltk; nltk.download('all')"

# Download spaCy models
python -m spacy download en_core_web_sm
python -m spacy download fr_core_news_sm
\`\`\`

---

## üìñ Learning Outcomes

By completing these laboratory exercises, students will gain:

- ‚úÖ Proficiency in text preprocessing and normalization techniques
- ‚úÖ Understanding of various feature extraction methods
- ‚úÖ Hands-on experience with word embeddings (Word2Vec, GloVe)
- ‚úÖ Knowledge of sequence modeling architectures (RNN, LSTM, GRU)
- ‚úÖ Practical skills in building neural machine translation systems
- ‚úÖ Experience with modern NLP frameworks and libraries

---

## üéì Course Information

**Institution:** Higher School of Computer Science (ESI - 08 May 1945)  
**Location:** Sidi Bel Abbes, Algeria  
**Program:** Master's Degree in Artificial Intelligence & Data Science  
**Year:** 1st Year Master's  
**Course:** Natural Language Processing

---

## üìù License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

---

<div align="center">

**Made with ‚ù§Ô∏è for NLP Learning**

*If you find this repository helpful, please consider giving it a ‚≠ê*

</div>
